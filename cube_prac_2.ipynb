{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBbqyVw4L2FS3nGhI9TOuI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithecs-biomath/mini-schools/blob/main/cube_prac_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BUILDING DATA CUBES\n",
        "## NITheCS mini school: lecture 2"
      ],
      "metadata": {
        "id": "Bp-W-sJLJqBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install missing packages"
      ],
      "metadata": {
        "id": "m3k-vt2-Kn6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pygbif"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IOS7pGoZKlrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Only execute the following block when using the TPU kernel"
      ],
      "metadata": {
        "id": "dS-zYQ1hwGUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install geopandas\n",
        "%pip install pydrive\n",
        "%pip install ee\n",
        "%pip install eerepr\n",
        "%pip install geemap"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gO159TjOWCid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading packages"
      ],
      "metadata": {
        "id": "0YVVvbzPKIjD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrSam0SbJh5u"
      },
      "outputs": [],
      "source": [
        "from pygbif import occurrences as occ\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from pyproj import Proj, Transformer\n",
        "from shapely.geometry import mapping\n",
        "from shapely.geometry import Polygon\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "import zipfile\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Earth Engine"
      ],
      "metadata": {
        "id": "ChCUCVVGnkJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import eerepr\n",
        "import geemap\n",
        "\n",
        "ee.Authenticate(force=True)\n",
        "ee.Initialize(project='nithecs-436810')\n",
        "\n",
        "LANDSAT_ID = \"LANDSAT/LC08/C02/T1_L2\"\n",
        "BOUNDARIES_ID = 'FAO/GAUL/2015/level1'\n",
        "WDPA_ID = 'WCMC/WDPA/current/polygons'\n",
        "SENTINEL_ID = \"COPERNICUS/S2_SR_HARMONIZED\"\n",
        "\n",
        "\n",
        "dataset = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2').filterDate('2021-05-01', '2021-06-01')\n",
        "sa = ee.FeatureCollection(BOUNDARIES_ID).filter(\n",
        "    'ADM0_NAME == \"South Africa\"')\n",
        "\n",
        "dataset_eo = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterDate('2020-01-01', '2020-01-30')\n",
        "\n",
        "protected_areas = ee.FeatureCollection(WDPA_ID)\n",
        "\n",
        "\n",
        "sa_landsat = dataset.filterBounds(sa)\n",
        "sa_sentinel = dataset_eo.filterBounds(sa)\n"
      ],
      "metadata": {
        "id": "7Ez39Bq5nn5O",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example of the GBIF API through pygbif"
      ],
      "metadata": {
        "id": "0zQ_dL3I24ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pygbif import occurrences\n",
        "data = occurrences.search(speciesKey=5229490, limit=10)\n",
        "\n",
        "print(data['results'])"
      ],
      "metadata": {
        "id": "HXKgmN_o2-Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GBIF data Cubes"
      ],
      "metadata": {
        "id": "GQqyBJJ9C5Pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating the Cube"
      ],
      "metadata": {
        "id": "DSo7FAhnC8z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exemplar JSON query for generating a data *cube*"
      ],
      "metadata": {
        "id": "uX6sbQm03N0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "{\n",
        "  \"sendNotification\": true,\n",
        "  \"notificationAddresses\": [\n",
        "    \"maarten.trekels@plantentuinmeise.be\"\n",
        "  ],\n",
        "  \"format\": \"SQL_TSV_ZIP\",\n",
        "  \"sql\": \"SELECT  PRINTF('%04d-%02d', \\\"year\\\", \\\"month\\\") AS yearMonth,\n",
        "   GBIF_EEARGCode(10000, decimalLatitude,  decimalLongitude,  COALESCE(coordinateUncertaintyInMeters, 1000) ) AS eeaCellCode,\n",
        "   speciesKey,\n",
        "   species,\n",
        "   establishmentMeans,\n",
        "   degreeOfEstablishment,\n",
        "   pathway,\n",
        "   COUNT(*) AS occurrences,\n",
        "   COUNT(DISTINCT recordedBy) AS distinctObservers\n",
        "   FROM  occurrence\n",
        "   WHERE occurrenceStatus = 'PRESENT'\n",
        "   AND countryCode = 'BE'\n",
        "   AND hasCoordinate = TRUE\n",
        "   AND NOT ARRAY_CONTAINS(issue, 'ZERO_COORDINATE')\n",
        "   AND NOT ARRAY_CONTAINS(issue, 'COORDINATE_OUT_OF_RANGE')\n",
        "   AND NOT ARRAY_CONTAINS(issue, 'COORDINATE_INVALID')\n",
        "   AND NOT ARRAY_CONTAINS(issue, 'COUNTRY_COORDINATE_MISMATCH')\n",
        "   AND \\\"month\\\" IS NOT NULL\n",
        "   GROUP BY yearMonth,\n",
        "   eeaCellCode,\n",
        "   speciesKey,\n",
        "   species,\n",
        "   establishmentMeans,\n",
        "   degreeOfEstablishment,\n",
        "   pathway\n",
        "   ORDER BY  yearMonth DESC,\n",
        "   eeaCellCode ASC,\n",
        "   speciesKey ASC\"\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "4qMrzQTgFgER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using the GBIF Download UI\n",
        "\n",
        "https://techdocs.gbif.org/en/data-use/api-sql-downloads"
      ],
      "metadata": {
        "id": "ZM8YPdG6FyjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data cube in pandas\n",
        "\n"
      ],
      "metadata": {
        "id": "pXUvmd6QDGLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download from GitHub"
      ],
      "metadata": {
        "id": "-kR_gUExFO8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can download a pre generated data cube from GitHub or any other online resource"
      ],
      "metadata": {
        "id": "sGaKM_TS3p3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data = pd.read_csv('https://raw.githubusercontent.com/nithecs-biomath/mini-schools/refs/heads/main/data/sample_data_SA.csv', sep='\\t')\n",
        "\n",
        "#print(data)"
      ],
      "metadata": {
        "id": "P5d8QfCMFckh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download from Google Drive"
      ],
      "metadata": {
        "id": "I0s-V9leloxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "data = pd.read_csv('/content/drive/Shareddrives/NiTheCS mini school/demo_data/Cube_ZA_QDGC_l3.csv', sep='\\t')\n"
      ],
      "metadata": {
        "id": "inbT_rtJln3u",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "3rxQZV4aUGVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting a Geopackage file from the Grid that you use"
      ],
      "metadata": {
        "id": "fTxMkKTT37NW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load QDGC code\n",
        "\n",
        "input_file = \"/content/drive/Shareddrives/NiTheCS mini school/demo_data/qdgc_south_africa.gpkg\"\n",
        "\n",
        "qdgc_ref = gpd.read_file(input_file, layer='tbl_qdgc_03')"
      ],
      "metadata": {
        "id": "vqB4Zzmq6T9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qdgc_ref)"
      ],
      "metadata": {
        "id": "F65_FA673MVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging the Data cube with the grid"
      ],
      "metadata": {
        "id": "s7yCjOV04Mrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testing if I can merge data and qdgc\n",
        "\n",
        "test_merge = pd.merge(data, qdgc_ref, left_on='qdgccode', right_on='qdgc')\n",
        "\n",
        "print(test_merge)\n"
      ],
      "metadata": {
        "id": "nMBOoVkS-YY-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to GeoDataFrame\n",
        "\n",
        "gdf = gpd.GeoDataFrame(test_merge, geometry='geometry')\n"
      ],
      "metadata": {
        "id": "rS9_Ly7UcssD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the CRS and convert to a GeoParquet file\n",
        "gdf = gdf.set_crs(epsg=4326, inplace=False)\n",
        "\n",
        "gdf.to_parquet('/content/drive/Shareddrives/NiTheCS mini school/demo_data/data_ZA.parquet')"
      ],
      "metadata": {
        "id": "lv5Js7o5AoTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data directly as Parquet files\n"
      ],
      "metadata": {
        "id": "Sehi9diVGszl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "gbif_cube = '/content/drive/Shareddrives/NiTheCS mini school/demo_data/data_ZA.parquet'\n",
        "gbif_points = '/content/drive/Shareddrives/NiTheCS mini school/demo_data/data_ZA_occurrence.parquet'\n",
        "\n",
        "gdf_cube = gpd.read_parquet(gbif_cube)\n",
        "gdf_point = gpd.read_parquet(gbif_points)"
      ],
      "metadata": {
        "id": "ykyzuL5WGyts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering data (e.g. on species)\n",
        "\n",
        "Check for a single species (Acacia implexa Benth.: https://www.gbif.org/species/2979232)\n",
        "\n"
      ],
      "metadata": {
        "id": "aBJXy6Ai42OY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check for a single species\n",
        "gdf_cube = gdf_cube[gdf_cube['specieskey'].eq(2979232)]\n",
        "gdf_point = gdf_point[gdf_point['speciesKey'].eq(2979232.0)]\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Umo4nXvKgLUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply the function to create a list of features"
      ],
      "metadata": {
        "id": "bg5ZzwXY54Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert GeoDataFrames to GeoJSON FeatureCollections\n",
        "def gdf_to_ee_featurecollection(gdf):\n",
        "    return geemap.geopandas_to_ee(gdf, geodesic=False)\n",
        "\n",
        "# Assuming gdf1 and gdf2 are your GeoDataFrames\n",
        "fc1 = gdf_to_ee_featurecollection(gdf_cube)\n",
        "fc2 = gdf_to_ee_featurecollection(gdf_point)"
      ],
      "metadata": {
        "id": "rNFsTUkWPUQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization of the data cubes on a map with different layers"
      ],
      "metadata": {
        "id": "1w6Mlltx6BxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a map centered on your data\n",
        "center = (-33.97, 18.58)\n",
        "\n",
        "Map = geemap.Map(layout={\"height\": \"500px\", \"width\": \"1000px\"}, center=center, zoom=10)\n",
        "\n",
        "\n",
        "visualization = {\n",
        "    'min': 0.0,\n",
        "    'max': 0.3,\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "}\n",
        "\n",
        "# Add FeatureCollections to the map\n",
        "Map.addLayer(fc1, {'color': 'red'}, 'Data Cube')\n",
        "Map.addLayer(fc2, {'color': 'blue'}, 'Point data')\n",
        "\n",
        "\n",
        "#Map.addLayer(sa_sentinel, visualization, 'RGB Sentinel 2')\n",
        "\n",
        "#Map.addLayer(protected_areas)\n",
        "\n",
        "\n",
        "# Visualise the map\n",
        "Map"
      ],
      "metadata": {
        "id": "tR4SI5CYK1Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Test with NetCDF format"
      ],
      "metadata": {
        "id": "eEz3_PvTQqSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EBV data cubes in NetCDF format\n",
        "\n",
        "https://portal.geobon.org/datasets"
      ],
      "metadata": {
        "id": "WxgVa_if6SIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install netCDF4"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yL6pmxznRZeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install rioxarray\n",
        "%pip install cartopy\n",
        "%pip install basemap"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xCUcxx3a6Mat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import netCDF4 as nc\n",
        "import xarray as xr\n",
        "\n",
        "\n",
        "birds_file = xr.open_dataset('/content/drive/Shareddrives/NiTheCS mini school/demo_data/viti_spepop_id77_20240206_v1.nc')\n",
        "\n",
        "print(birds_file)"
      ],
      "metadata": {
        "id": "UQBa7ytzQtOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_netcdf_structure(nc_file_path):\n",
        "  \"\"\"Prints the structure (groups, variables, and their paths) of a NetCDF file.\n",
        "\n",
        "  Args:\n",
        "    nc_file_path: Path to the NetCDF file.\n",
        "  \"\"\"\n",
        "  def print_group_structure(group, path=\"\"):\n",
        "    \"\"\"Recursively prints the structure of a group within the NetCDF file.\"\"\"\n",
        "    for var_name in group.variables:\n",
        "      print(f\"{path}/{var_name}\")  # Print variable path\n",
        "    for group_name in group.groups:\n",
        "      subgroup = group.groups[group_name]\n",
        "      print_group_structure(subgroup, f\"{path}/{group_name}\")  # Recursively explore subgroups\n",
        "\n",
        "  with nc.Dataset(nc_file_path, 'r') as nc_file:\n",
        "    print_group_structure(nc_file)  # Start with the root group\n",
        "\n",
        "# Example usage:\n",
        "nc_file_path = '/content/drive/Shareddrives/NiTheCS mini school/demo_data/viti_spepop_id77_20240206_v1.nc'\n",
        "print_netcdf_structure(nc_file_path)"
      ],
      "metadata": {
        "id": "sVx0ayTMJQjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(birds_file.variables)"
      ],
      "metadata": {
        "id": "FAwpNOjVJYWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = birds_file.variables['time']\n",
        "print(time)\n",
        "\n",
        "print(birds_file['entity'])"
      ],
      "metadata": {
        "id": "Ix26108LJbKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "from pyproj import Transformer\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
        "\n",
        "# --- Load Dataset Efficiently ---\n",
        "birds_file = xr.open_dataset(\n",
        "    '/content/drive/Shareddrives/NiTheCS mini school/demo_data/viti_spepop_id77_20240206_v1.nc',\n",
        "    group=\"metric_1\",\n",
        "    chunks={'entity': 1, 'time': 1}  # Load only one entity/time slice at a time\n",
        ")\n",
        "\n",
        "# --- Select Target Species and Time ---\n",
        "species_index = 150  # Change to the species index you need\n",
        "time_index = 0  # Change to the desired time index\n",
        "\n",
        "# Extract only the required slice\n",
        "species_data_subset = birds_file['ebv_cube'].sel(entity=species_index, time=time_index).compute()\n",
        "\n",
        "# Convert to a 2D array\n",
        "species_distribution_2d = np.squeeze(species_data_subset)\n",
        "\n",
        "# --- Load Longitude and Latitude (Only Once) ---\n",
        "with xr.open_dataset('/content/drive/Shareddrives/NiTheCS mini school/demo_data/viti_spepop_id77_20240206_v1.nc') as ds:\n",
        "    lon = ds['lon'].values  # 1D array (size: 559)\n",
        "    lat = ds['lat'].values  # 1D array (size: 437)\n",
        "\n",
        "# --- Create Meshgrid Efficiently ---\n",
        "lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
        "\n",
        "# --- Efficient Coordinate Transformation ---\n",
        "transformer = Transformer.from_crs(\"epsg:3035\", \"epsg:4326\", always_xy=True)\n",
        "\n",
        "# Transform the entire 2D meshgrid\n",
        "lon_deg, lat_deg = transformer.transform(lon_grid, lat_grid)\n",
        "\n",
        "# --- Create the Plot ---\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
        "\n",
        "# Add map features\n",
        "ax.coastlines()\n",
        "ax.add_feature(cfeature.LAND, edgecolor='black', facecolor='lightgray')\n",
        "\n",
        "# --- 🔹 Fix: Use Discrete Colormap Without Color Bar ---\n",
        "unique_values = np.unique(species_distribution_2d)\n",
        "\n",
        "# If only one value, choose a single solid color\n",
        "if len(unique_values) == 1:\n",
        "    cmap = ListedColormap([\"red\"])  # Single-color for uniform data\n",
        "    norm = None\n",
        "else:\n",
        "    cmap = ListedColormap([\"white\", \"blue\"])  # Adjust colors as needed\n",
        "    norm = BoundaryNorm([0, 0.5, 1], cmap.N)\n",
        "\n",
        "# --- 🔹 Fix: Use `shading=\"nearest\"` to Ensure Correct Grid Alignment ---\n",
        "cs = ax.pcolormesh(\n",
        "    lon_deg, lat_deg, species_distribution_2d,\n",
        "    transform=ccrs.PlateCarree(),\n",
        "    cmap=cmap,\n",
        "    norm=norm,\n",
        "    shading='nearest'  # Prevents visual distortion\n",
        ")\n",
        "\n",
        "# --- 🔹 Completely Remove Color Bar ---\n",
        "# No `fig.colorbar(cs)`, so no scale bar will be shown\n",
        "\n",
        "# --- Get the Species Name Efficiently ---\n",
        "with xr.open_dataset('/content/drive/Shareddrives/NiTheCS mini school/demo_data/viti_spepop_id77_20240206_v1.nc') as ds:\n",
        "    species_name = ds['entity'].values[species_index].decode('utf-8').strip()\n",
        "\n",
        "# --- Final Plot Customization ---\n",
        "ax.set_title(f\"Species {species_name} Distribution (10x10 km grid) at time {birds_file['time'].values[time_index].item()}\")\n",
        "ax.set_xlabel(\"Longitude\")\n",
        "ax.set_ylabel(\"Latitude\")\n",
        "\n",
        "# --- 🔹 Fix: Add Grid Lines to Show Exact 10x10 km Cells ---\n",
        "gridlines = ax.gridlines(draw_labels=True, linestyle=\"--\", linewidth=0.5, color=\"black\", alpha=0.5)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q49V9ogqJgLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cd2wEV9tSAG0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}