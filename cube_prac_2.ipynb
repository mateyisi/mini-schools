{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyONDDZj0UmhwOlubA7yN3zw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithecs-biomath/mini-schools/blob/main/cube_prac_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BUILDING DATA CUBES\n",
        "## NITheCS mini school: lecture 2"
      ],
      "metadata": {
        "id": "Bp-W-sJLJqBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install missing packages"
      ],
      "metadata": {
        "id": "m3k-vt2-Kn6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pygbif\n",
        "%pip install mgrs"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IOS7pGoZKlrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Only execute the following block when using the TPU kernel"
      ],
      "metadata": {
        "id": "dS-zYQ1hwGUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install geopandas\n",
        "%pip install pydrive\n",
        "%pip install ee\n",
        "%pip install eerepr\n",
        "%pip install geemap"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gO159TjOWCid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading packages"
      ],
      "metadata": {
        "id": "0YVVvbzPKIjD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrSam0SbJh5u"
      },
      "outputs": [],
      "source": [
        "from pygbif import occurrences as occ\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from pyproj import Proj, Transformer\n",
        "from shapely.geometry import mapping\n",
        "from shapely.geometry import Polygon\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "import zipfile\n",
        "import mgrs\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Earth Engine"
      ],
      "metadata": {
        "id": "ChCUCVVGnkJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import eerepr\n",
        "import geemap\n",
        "\n",
        "ee.Authenticate(force=True)\n",
        "ee.Initialize(project='nithecs-436810')\n",
        "\n",
        "LANDSAT_ID = \"LANDSAT/LC08/C02/T1_L2\"\n",
        "BOUNDARIES_ID = 'FAO/GAUL/2015/level1'\n",
        "WDPA_ID = 'WCMC/WDPA/current/polygons'\n",
        "\n",
        "\n",
        "dataset = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2').filterDate('2021-05-01', '2021-06-01')\n",
        "sa = ee.FeatureCollection(BOUNDARIES_ID).filter(\n",
        "    'ADM0_NAME == \"South Africa\"')\n",
        "\n",
        "protected_areas = ee.FeatureCollection(WDPA_ID)\n",
        "\n",
        "\n",
        "sa_landsat = dataset.filterBounds(sa)\n"
      ],
      "metadata": {
        "id": "7Ez39Bq5nn5O",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example of the GBIF API through pygbif"
      ],
      "metadata": {
        "id": "0zQ_dL3I24ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pygbif import occurrences\n",
        "data = occurrences.search(speciesKey=5229490, limit=10)\n",
        "\n",
        "print(data['results'])"
      ],
      "metadata": {
        "id": "HXKgmN_o2-Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GBIF data Cubes"
      ],
      "metadata": {
        "id": "GQqyBJJ9C5Pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating the Cube"
      ],
      "metadata": {
        "id": "DSo7FAhnC8z2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exemplar JSON query for generating a data cube"
      ],
      "metadata": {
        "id": "uX6sbQm03N0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"sendNotification\": true,\n",
        "  \"notificationAddresses\": [\n",
        "    \"maarten.trekels@plantentuinmeise.be\"\n",
        "  ],\n",
        "  \"format\": \"SQL_TSV_ZIP\",\n",
        "  \"sql\": \"SELECT  PRINTF('%04d-%02d', \\\"year\\\", \\\"month\\\") AS yearMonth,\n",
        "   GBIF_EEARGCode(10000, decimalLatitude,  decimalLongitude,  COALESCE(coordinateUncertaintyInMeters, 1000) ) AS eeaCellCode,\n",
        "   speciesKey,\n",
        "   species,\n",
        "   establishmentMeans,\n",
        "   degreeOfEstablishment,\n",
        "   pathway,\n",
        "   COUNT(*) AS occurrences,\n",
        "   COUNT(DISTINCT recordedBy) AS distinctObservers\n",
        "   FROM  occurrence\n",
        "   WHERE occurrenceStatus = 'PRESENT'\n",
        "   AND countryCode = 'BE'\n",
        "   AND hasCoordinate = TRUE\n",
        "   AND NOT ARRAY_CONTAINS(issue, 'ZERO_COORDINATE')\n",
        "   AND NOT ARRAY_CONTAINS(issue, 'COORDINATE_OUT_OF_RANGE')\n",
        "   AND NOT ARRAY_CONTAINS(issue, 'COORDINATE_INVALID')\n",
        "   AND NOT ARRAY_CONTAINS(issue, 'COUNTRY_COORDINATE_MISMATCH')\n",
        "   AND \\\"month\\\" IS NOT NULL\n",
        "   GROUP BY yearMonth,\n",
        "   eeaCellCode,\n",
        "   speciesKey,\n",
        "   species,\n",
        "   establishmentMeans,\n",
        "   degreeOfEstablishment,\n",
        "   pathway\n",
        "   ORDER BY  yearMonth DESC,\n",
        "   eeaCellCode ASC,\n",
        "   speciesKey ASC\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "j-4mKguQC_Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data cube in pandas\n",
        "\n"
      ],
      "metadata": {
        "id": "pXUvmd6QDGLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Dzx-QCLxllhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download from GitHub"
      ],
      "metadata": {
        "id": "-kR_gUExFO8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can download a pre generated data cube from GitHub or any other online resource"
      ],
      "metadata": {
        "id": "sGaKM_TS3p3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data = pd.read_csv('https://raw.githubusercontent.com/nithecs-biomath/mini-schools/refs/heads/main/data/sample_data_SA.csv', sep='\\t')\n",
        "\n",
        "#print(data)"
      ],
      "metadata": {
        "id": "P5d8QfCMFckh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download from Google Drive"
      ],
      "metadata": {
        "id": "I0s-V9leloxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "data = pd.read_csv('/content/drive/Shareddrives/NiTheCS mini school/demo_data/Cube_ZA_QDGC_l3.csv', sep='\\t')\n"
      ],
      "metadata": {
        "id": "inbT_rtJln3u",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "3rxQZV4aUGVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting a Geopackage file from the Grid that you use"
      ],
      "metadata": {
        "id": "fTxMkKTT37NW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load QDGC code\n",
        "\n",
        "input_file = \"/content/drive/Shareddrives/NiTheCS mini school/demo_data/qdgc_south_africa.gpkg\"\n",
        "\n",
        "qdgc_ref = gpd.read_file(input_file, layer='tbl_qdgc_03')"
      ],
      "metadata": {
        "id": "vqB4Zzmq6T9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qdgc_ref)"
      ],
      "metadata": {
        "id": "F65_FA673MVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging the Data cube with the grid"
      ],
      "metadata": {
        "id": "s7yCjOV04Mrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testing if I can merge data and qdgc\n",
        "\n",
        "test_merge = pd.merge(data, qdgc_ref, left_on='qdgccode', right_on='qdgc')\n",
        "\n",
        "print(test_merge)\n"
      ],
      "metadata": {
        "id": "nMBOoVkS-YY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to GeoDataFrame\n",
        "\n",
        "gdf = gpd.GeoDataFrame(test_merge, geometry='geometry')\n"
      ],
      "metadata": {
        "id": "rS9_Ly7UcssD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering data (e.g. on species)"
      ],
      "metadata": {
        "id": "aBJXy6Ai42OY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check for a single species\n",
        "filtered_gdf = gdf[gdf['specieskey'].eq(2435350.0)]\n",
        "\n",
        "print(filtered_gdf)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Umo4nXvKgLUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply the function to create a list of features"
      ],
      "metadata": {
        "id": "bg5ZzwXY54Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filtered_gdf = filtered_gdf.set_crs(epsg=4326, inplace=False)\n",
        "\n",
        "data_raw = geemap.geopandas_to_ee(filtered_gdf)\n",
        "\n",
        "print(type(data_raw))\n"
      ],
      "metadata": {
        "id": "rNFsTUkWPUQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization of the data cubes on a map with different layers"
      ],
      "metadata": {
        "id": "1w6Mlltx6BxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map(layout={\"height\": \"400px\", \"width\": \"800px\"})\n",
        "\n",
        "\n",
        "# Add the original data layer in blue\n",
        "Map.addLayer(data_raw, {\"color\": \"blue\"}, \"Original data\")\n",
        "\n",
        "Map.addLayer(sa_landsat)\n",
        "\n",
        "Map.addLayer(protected_areas)\n",
        "\n",
        "\n",
        "# Set the center of the map to the coordinates\n",
        "Map.setCenter(-28.50, 29.41)\n",
        "Map"
      ],
      "metadata": {
        "id": "tR4SI5CYK1Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Test with NetCDF format"
      ],
      "metadata": {
        "id": "eEz3_PvTQqSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EBV data cubes in NetCDF format"
      ],
      "metadata": {
        "id": "WxgVa_if6SIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install netCDF4"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yL6pmxznRZeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install rioxarray\n",
        "%pip install cartopy\n",
        "%pip install basemap"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xCUcxx3a6Mat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import netCDF4 as nc\n",
        "import xarray as xr\n",
        "\n",
        "\n",
        "birds_file = xr.open_dataset('/content/drive/Shareddrives/NiTheCS mini school/demo_data/viti_spepop_id77_20240206_v1.nc')\n",
        "\n",
        "print(birds_file)"
      ],
      "metadata": {
        "id": "UQBa7ytzQtOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(birds_file.variables)"
      ],
      "metadata": {
        "id": "zeG8VT7ORqqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time = birds_file.variables['time']\n",
        "print(time)\n",
        "\n",
        "print(birds_file['entity'])"
      ],
      "metadata": {
        "id": "W8MS244jYNDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a detailed view of all data variables\n",
        "for var in birds_file.data_vars:\n",
        "    print(f\"Variable: {var}\")\n",
        "    print(birds_file[var])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "m_q4fCoNGF0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(birds_file['entity'].values)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3wfFUzYKkEBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from netCDF4 import Dataset as NetCDFFile\n",
        "from mpl_toolkits.basemap import Basemap\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "rvt1OCVIlh5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ykjsl2LXSpVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nc = NetCDFFile('/content/drive/Shareddrives/NiTheCS mini school/demo_data/viti_spepop_id77_20240206_v1.nc')"
      ],
      "metadata": {
        "id": "q2PE68Z25Nsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nc)"
      ],
      "metadata": {
        "id": "6I-xyzWceudd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lat = nc.variables['lat'][:]\n",
        "lon = nc.variables['lon'][:]\n",
        "time = nc.variables['time'][:]"
      ],
      "metadata": {
        "id": "pXB_h0Fx5aZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crs = nc.variables['crs'][:]\n",
        "ent = nc.variables['entity'][:]"
      ],
      "metadata": {
        "id": "MAWn4F9N5qi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities = nc.variables['entity'][:]\n",
        "print(entities)\n",
        "species_names = [''.join(entity.astype(str)).strip() for entity in entities]\n",
        "\n",
        "# Print the species names for inspection\n",
        "for idx, species in enumerate(species_names):\n",
        "    print(f'{idx}: {species}')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PewlSmV5kAEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nc.groups['metric_1'].variables)"
      ],
      "metadata": {
        "id": "5jO1jE-xlVop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyproj import Proj, transform\n",
        "\n",
        "# Define the EPSG:3035 and EPSG:4326 projections\n",
        "proj3035 = Proj(init='epsg:3035')\n",
        "proj4326 = Proj(init='epsg:4326')\n",
        "\n",
        "# Convert lon and lat arrays from meters (EPSG:3035) to degrees (EPSG:4326)\n",
        "lon_deg, lat_deg = transform(proj3035, proj4326, lon, lat)\n",
        "\n",
        "# Now lon_deg and lat_deg are in degrees, and can be used with the 'aea' projection in Basemap\n"
      ],
      "metadata": {
        "id": "whNv8yvieOT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp = Basemap(projection='aea', ellps='WGS84', lon_0=10, lat_0=52, lat_1=37, lat_2=62,\n",
        "            llcrnrlon=min(lon_deg.flatten()), llcrnrlat=min(lat_deg.flatten()),\n",
        "            urcrnrlon=max(lon_deg.flatten()), urcrnrlat=max(lat_deg.flatten()))\n"
      ],
      "metadata": {
        "id": "ANMayB0seTAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "species_index = 10\n",
        "\n",
        "species_distribution = nc.groups['metric_1'].variables['ebv_cube'][species_index, :, :]"
      ],
      "metadata": {
        "id": "u8NskKrVk8He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'lon shape: {lon.shape}')\n",
        "print(f'lat shape: {lat.shape}')\n",
        "print(f'species_distribution shape: {species_distribution_2d.shape}')\n",
        "\n",
        "species_distribution_2d = np.squeeze(species_distribution)\n",
        "# Mask NaN values in the species distribution data\n",
        "species_distribution_masked = np.ma.masked_invalid(species_distribution_2d)"
      ],
      "metadata": {
        "id": "TnO2ZvEoTaK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lon)"
      ],
      "metadata": {
        "id": "Xe0zE5DWZTWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lon, lat = np.meshgrid(lon,lat)  #this converts coordinates into 2D arrray\n",
        "x, y = mp(lon,lat) #mapping them together\n",
        "\n",
        "cs = mp.pcolormesh(x, y, species_distribution_masked, cmap='YlGn', shading='auto')\n",
        "\n",
        "# consider this as the outline for the map that is to be created\n",
        "mp.drawcoastlines()\n",
        "mp.drawstates()\n",
        "mp.drawcountries()\n",
        "#plt.colorbar(cs, label='Species Distribution')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9I3Rcyykg6vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RqlEjchyhcQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random functions to test: do not use! :-)"
      ],
      "metadata": {
        "id": "ChfUoEM04kp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert QDGC to lat/long bounding box\n",
        "def qdgc_to_polygon(qdgc):\n",
        "    # Parse the longitude and latitude\n",
        "    lon_deg = int(qdgc[1:4])  # Extract longitude value\n",
        "    lat_deg = int(qdgc[5:7])  # Extract latitude value\n",
        "\n",
        "    if qdgc[0] == 'W':  # Western Hemisphere\n",
        "        lon_deg = -lon_deg\n",
        "    if qdgc[4] == 'S':  # Southern Hemisphere\n",
        "        lat_deg = -lat_deg\n",
        "\n",
        "    # Subdivision (AA, AB, BB, etc.)\n",
        "    subcell = qdgc[7:]\n",
        "\n",
        "    # Quarter-degree grid size (0.25° x 0.25°)\n",
        "    quarter_degree_size = 1\n",
        "\n",
        "    # Subdivision within quarter-degree cells (1/4 of 0.25° = 0.0625°)\n",
        "    subcell_size = quarter_degree_size / 4  # Each smaller cell is 0.0625° x 0.0625°\n",
        "\n",
        "    # Mapping the subcell to the grid position (AA, AB, ..., DD)\n",
        "    subcell_map = {\n",
        "        'AA': (0, 0), 'AB': (subcell_size, 0), 'AC': (2 * subcell_size, 0), 'AD': (3 * subcell_size, 0),\n",
        "        'BA': (0, subcell_size), 'BB': (subcell_size, subcell_size), 'BC': (2 * subcell_size, subcell_size), 'BD': (3 * subcell_size, subcell_size),\n",
        "        'CA': (0, 2 * subcell_size), 'CB': (subcell_size, 2 * subcell_size), 'CC': (2 * subcell_size, 2 * subcell_size), 'CD': (3 * subcell_size, 2 * subcell_size),\n",
        "        'DA': (0, 3 * subcell_size), 'DB': (subcell_size, 3 * subcell_size), 'DC': (2 * subcell_size, 3 * subcell_size), 'DD': (3 * subcell_size, 3 * subcell_size)\n",
        "    }\n",
        "\n",
        "    lon_shift, lat_shift = subcell_map[subcell]\n",
        "\n",
        "    # Find the top-left corner of the quarter-degree grid\n",
        "    lon_min = lon_deg + (0 if qdgc[0] == 'W' else 0.0)\n",
        "    lat_min = lat_deg + (0 if qdgc[4] == 'S' else 0.0)\n",
        "\n",
        "    # Shift by the quarter-degree for the QDGC part (quarter-degree grid)\n",
        "    lon_min += lon_shift\n",
        "    lat_min += lat_shift\n",
        "\n",
        "    # Calculate maximum lat and lon\n",
        "    lat_max = lat_min + subcell_size\n",
        "    lon_max = lon_min + subcell_size\n",
        "\n",
        "    # Create the polygon for the grid cell\n",
        "    return Polygon([(lon_min, lat_min), (lon_max, lat_min), (lon_max, lat_max), (lon_min, lat_max), (lon_min, lat_min)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Apply function to get polygons\n",
        "#df = pd.DataFrame(data['qdgccode'].unique())\n",
        "\n",
        "\n",
        "\n",
        "#ata['geometry'] = data['qdgccode'].apply(qdgc_to_polygon)\n",
        "data['geometry'] = data['qdgccode'].apply(qdgc_to_polygon)\n",
        "#geom = qdgc_to_polygon(df[0].values())\n"
      ],
      "metadata": {
        "id": "zcSuJ42vEUac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert meters to degrees for latitude and longitude\n",
        "def meters_to_degrees(lat, meters):\n",
        "    # 1 degree latitude is roughly 111.32 km (constant)\n",
        "    deg_lat = meters / 111320\n",
        "\n",
        "    # 1 degree longitude is 111.32 km * cos(latitude) (varies with latitude)\n",
        "    deg_lon = meters / (111320 * math.cos(math.radians(lat)))\n",
        "\n",
        "    return deg_lat, deg_lon\n",
        "\n",
        "# Function to convert MGRS to polygon\n",
        "def mgrs_to_polygon(mgrs_code):\n",
        "    mgrs_converter = mgrs.MGRS()\n",
        "\n",
        "    # Get lower-left corner of MGRS grid square (lat, lon)\n",
        "    lat, lon = mgrs_converter.toLatLon(mgrs_code)\n",
        "\n",
        "    # Determine grid size in meters based on MGRS precision\n",
        "    # Example: Adjust according to precision (1000m for 4-character code, etc.)\n",
        "    grid_size_meters = 10000  # Adjust based on precision of MGRS code\n",
        "\n",
        "    # Convert meters to degrees at the given latitude\n",
        "    grid_size_lat_deg, grid_size_lon_deg = meters_to_degrees(lat, grid_size_meters)\n",
        "\n",
        "    # Create polygon points for the grid square\n",
        "    polygon_points = [\n",
        "        (lon, lat),  # lower-left\n",
        "        (lon + grid_size_lon_deg, lat),  # lower-right\n",
        "        (lon + grid_size_lon_deg, lat + grid_size_lat_deg),  # upper-right\n",
        "        (lon, lat + grid_size_lat_deg)  # upper-left\n",
        "    ]\n",
        "\n",
        "    # Create the polygon using shapely\n",
        "    polygon = Polygon(polygon_points)\n",
        "\n",
        "    return polygon\n",
        "\n",
        "m = mgrs.MGRS()\n",
        "# Function to convert MGRS to UTM polygon\n",
        "def mgrs_to_utm_polygon(mgrs_code):\n",
        "    # Convert MGRS to lat/lon using the mgrs library\n",
        "\n",
        "    lat, lon = m.toLatLon(mgrs_code)  # Get lower-left corner in lat/lon\n",
        "\n",
        "    # Extract UTM zone number from the MGRS code (first two digits are the UTM zone)\n",
        "    utm_zone_number = int(mgrs_code[:2])\n",
        "\n",
        "    # Determine if it's in the northern or southern hemisphere based on the latitude band\n",
        "    hemisphere = 'north' if mgrs_code[2].upper() >= 'N' else 'south'\n",
        "\n",
        "    # Create UTM projection based on the zone number and hemisphere\n",
        "    utm_proj = Proj(proj='utm', zone=utm_zone_number, ellps='WGS84', south=(hemisphere == 'south'))\n",
        "\n",
        "    # Transformer to convert lat/lon to UTM coordinates (EPSG:4326 -> UTM)\n",
        "    transformer_to_utm = Transformer.from_crs(\"epsg:4326\", utm_proj.srs)\n",
        "\n",
        "    # Transform the lower-left corner from lat/lon to UTM (meters)\n",
        "    x_utm, y_utm = transformer_to_utm.transform(lat, lon)\n",
        "\n",
        "    # Define the grid size in meters (e.g., 1000 meters for a 1 km MGRS grid)\n",
        "    grid_size_meters = 10000  # Adjust based on the precision of your MGRS code\n",
        "\n",
        "    # Create the UTM polygon points (lower-left, lower-right, upper-right, upper-left)\n",
        "    utm_polygon_points = [\n",
        "        (x_utm, y_utm),                                 # lower-left\n",
        "        (x_utm + grid_size_meters, y_utm),              # lower-right\n",
        "        (x_utm + grid_size_meters, y_utm + grid_size_meters),  # upper-right\n",
        "        (x_utm, y_utm + grid_size_meters)               # upper-left\n",
        "    ]\n",
        "\n",
        "    # Create the polygon in UTM space\n",
        "    utm_polygon = Polygon(utm_polygon_points)\n",
        "\n",
        "    # Transformer to convert UTM coordinates back to lat/lon (UTM -> EPSG:4326)\n",
        "    transformer_to_latlon = Transformer.from_crs(utm_proj.srs, \"epsg:4326\")\n",
        "\n",
        "    # Transform the UTM polygon back to lat/lon coordinates\n",
        "    latlon_polygon = Polygon([transformer_to_latlon.transform(x, y) for x, y in utm_polygon.exterior.coords])\n",
        "\n",
        "    return latlon_polygon\n",
        "\n",
        "#data['geometry'] = data['mgrscode'].apply(mgrs_to_polygon)"
      ],
      "metadata": {
        "id": "K8fRWE28zCB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}